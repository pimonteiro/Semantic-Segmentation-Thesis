{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ca9269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import importlib  \n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from utils.keras_functions import sparse_crossentropy_ignoring_last_label, Jaccard\n",
    "import Keras_segmentation_deeplab_v3_1.utils\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d883ccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb699b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('pb_files/xception_freezed_mixed_attempt/') # path to the SavedModel directory\n",
    "converter.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b3d8ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data.\n",
    "#input_shape = input_details[0]['shape']\n",
    "#input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "#interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "#interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "#output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "#print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdce55ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (375,513)\n",
    "\n",
    "SegClass = Keras_segmentation_deeplab_v3_1.utils.SegModel(\"../kitti360_dataset_truncated.csv\", image_size=image_size)\n",
    "\n",
    "test_generator = SegClass.create_generators(dataset = \"../kitti360_dataset_truncated.csv\", blur=0, mode='test',\n",
    "                                                n_classes=19, horizontal_flip=False, vertical_flip=False, \n",
    "                                                brightness=0, rotation=False, zoom=0, batch_size=1,\n",
    "                                                seed=7, do_ahisteq=False, resize_shape=(375,513))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a73cf781",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = test_generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17acf73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Lite mean time:  35.77059507369995\n"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "for i in range(10):\n",
    "    start = time.time()\n",
    "    interpreter.set_tensor(input_details[0]['index'], x)\n",
    "    interpreter.invoke()\n",
    "    end = time.time()\n",
    "    times.append(end-start)\n",
    "\n",
    "print('Tensorflow Lite mean time: ', np.mean(times))\n",
    "\n",
    "#output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "#print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af96476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from PIL import Image\n",
    "\n",
    "def create_cityscapes_label_colormap():\n",
    "    colormap = np.zeros((256, 3), dtype=int)\n",
    "    ind = np.arange(256, dtype=int)\n",
    "\n",
    "    for shift in reversed(range(8)):\n",
    "        for channel in range(3):\n",
    "            colormap[:, channel] |= ((ind >> channel) & 1) << shift\n",
    "        ind >>= 3\n",
    "\n",
    "    return colormap\n",
    "\n",
    "\n",
    "def label_to_color_image(label):\n",
    "    if label.ndim != 2:\n",
    "        raise ValueError('Expect 2-D input label')\n",
    "\n",
    "    colormap = create_cityscapes_label_colormap()\n",
    "\n",
    "    if np.max(label) >= len(colormap):\n",
    "        raise ValueError('label value too large.')\n",
    "\n",
    "    return colormap[label]\n",
    "\n",
    "\n",
    "def vis_segmentation(image, seg_map):\n",
    "    \"\"\"Visualizes input image, segmentation map and overlay view.\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    grid_spec = gridspec.GridSpec(1, 4, width_ratios=[6, 6, 6, 1])\n",
    "\n",
    "    plt.subplot(grid_spec[0])\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('input image')\n",
    "\n",
    "    plt.subplot(grid_spec[1])\n",
    "    seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
    "    plt.imshow(seg_image)\n",
    "    plt.axis('off')\n",
    "    plt.title('segmentation map')\n",
    "\n",
    "    plt.subplot(grid_spec[2])\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(seg_image, alpha=0.7)\n",
    "    plt.axis('off')\n",
    "    plt.title('segmentation overlay')\n",
    "\n",
    "    unique_labels = np.unique(seg_map)\n",
    "    ax = plt.subplot(grid_spec[3])\n",
    "    plt.imshow(\n",
    "      FULL_COLOR_MAP[unique_labels].astype(np.uint8), interpolation='nearest')\n",
    "    ax.yaxis.tick_right()\n",
    "    plt.yticks(range(len(unique_labels)), LABEL_NAMES[unique_labels])\n",
    "    plt.xticks([], [])\n",
    "    ax.tick_params(width=0.0)\n",
    "    plt.grid('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "LABEL_NAMES = np.asarray(['road', 'sidewalk', 'building', 'wall', 'fence', 'pole', \n",
    "               'traffic light', 'traffic sign', 'vegetation', 'terraain', 'sky', 'person', \n",
    "               'rider', 'car', 'truck', 'bus', 'train', 'motorcycle', 'bicycle','unknown'])\n",
    "FULL_LABEL_MAP = np.arange(len(LABEL_NAMES)).reshape(len(LABEL_NAMES), 1)\n",
    "FULL_COLOR_MAP = label_to_color_image(FULL_LABEL_MAP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
